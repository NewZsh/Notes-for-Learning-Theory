\documentclass{article}
\usepackage[UTF8]{ctex}
\setmainfont{Calibri Light}
\usepackage{setspace}
\renewcommand{\baselinestretch}{1.2}
\usepackage{amsmath,bm}
\usepackage{amssymb}
\usepackage{ntheorem}
\usepackage{graphicx}
\usepackage{bbm}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=cyan,      
	urlcolor=red,
	citecolor=green,
}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem*{proof}{Proof}
\setlength{\parindent}{2em}
\author{Siheng Zhang\\zhangsiheng@cvte.com}
\title{Chapter \textbf{\textit{3}}\ \ \ \ 生成模型}
\date{\today}      
\usepackage[a4paper,left=18mm,right=18mm,top=25mm,bottom=25mm]{geometry} 
\begin{document}
\maketitle  

本章对应于\textbf{UML第24、31章，PRML第1、2章}，主要讨论以下问题：

\begin{itemize}
\item 贝叶斯最优准则需要估计特征的联合分布，这对实际应用带来了不可计算的困难，解决这个问题的关键是特征独立假设。
\item 进一步地，为了估计类条件概率，本章讨论了参数化方法，非参数化的方法相对独立，因此留到其它章节。
\item 通过估计潜在分布进行判别的模型，我们称之为生成式模型，包括朴素贝叶斯、混合高斯模型等等。注意到，估计概率密度是机器学习中最为一般化也更难的问题。判别式模型则通过优化目标函数来避免这个问题。
\item 但是，生成式模型和判别式模型之间也存在着紧密的关联。本章的最后将会从贝叶斯分类器推导出线性判别器。而再下一章，我们也会指出，为判别式模型添加约束项（通常是为了防止过拟合）本质上与某些先验假设下的生成模型等价。
\end{itemize}

\tableofcontents
\newpage

\section{朴素贝叶斯（Naive Bayes，NB）}

	回顾贝叶斯最优准则（\textit{第1章，Ex6}）：
	
	\begin{equation*}
	h_{\mathrm{Bayes}}(\bm{x}) = \arg\max\limits_{y\in\{0,1\}} p (Y=y|X=\bm{x})
	\end{equation*}
	
	为了刻画后验概率函数，我们需要$2^d$个参数，这意味着，所需样本的数量随着特征维数指数倍地增加。为了避免这个问题，需要假设给定标签时，各个特征相互独立，即：$p (X=\bm{x}|Y=y) = \prod_{i=1}^d p (X_i=x_i|Y=y)$。

	结合贝叶斯公式，贝叶斯最优准则可以简化为：
	
	\begin{equation}
	h_{\mathrm{Bayes}}(\bm{x}) = \arg\max\limits_{y\in\{0,1\}} p (Y=y) \prod_{i=1}^d p (X_i=x_i|Y=y)
	\end{equation}
其中待估计的参数为$2d + 1$个。我们使用极大似然法估计这些参数，得到的分类器称为朴素贝叶斯分类器。

\section{参数密度估计——极大似然法（Maximum Likelihood Estimation，MLE）}
	
	参数密度估计假设类条件概率的分布形式已知（当然，如果选取的分布与实际数据的真实分布相去甚远，则结果也是错的。因此，为了对数据分布做尽可能少的假设，非参数估计就大有用途。但是本章暂不讨论这部分），问题就在于估计分布的参数。给定一个独立同分布的训练集$S = (\bm{x}_1,\cdots,\bm{x}_m)$，$S$的似然可以由$\theta$表示，即$L(S;\theta) = \prod_{i=1}^m  p(\bm{x}_i;\theta)$。通常我们优化其对数形式，
	\begin{equation}
	\log L(S;\theta) = \sum_{i=1}^m \log p(\bm{x}_i;\theta)
	\end{equation}
下面对于常见分布给出参数估计的例子。推导过程略显繁琐，结论却浅显且符合直觉。

	\begin{itemize}
	\item [\textbf{1}] 伯努利（Bernoulli）分布，最大似然估计结果等于样本均值，$\theta_{\mathrm{ML}}=\sum_{i=1}^m x_i/m$，
	\vspace{1mm}
	\begin{scriptsize}
	\begin{spacing}{1.2}
	{\sffamily
	伯努利分布刻画了0-1变量$x$的概率，$x=1$的概率记为$\theta$，$x=0$的概率为$1-\theta$，即$p(x;\theta)=\theta^x(1-\theta)^{(1-x)}$。对应的对数似然函数为
	\begin{equation*}
	\log L(S;\theta) = \sum_{i=1}^m \log p(x_i;\theta) = \sum_{i=1}^m x_i\log \theta + (1-x_i)\log(1-\theta)
	\end{equation*}
对$\theta$求导并令导函数为0，可以得到：
	\begin{equation*}
	\frac{\partial \log L(S;\theta)}{\partial \theta} = \sum_{i=1}^m \frac{x_i}{\theta} - \frac{1-x_i}{1-\theta} = \sum_{i=1}^m \frac{x_i-\theta}{\theta(1-\theta)} = 0 \Longrightarrow	 \theta_{\mathrm{ML}}=\frac{1}{m}\sum_{i=1}^m x_i	
	\end{equation*}
	}
	\end{spacing}
	\end{scriptsize}
	\vspace{-4mm}
	
	\item [\textbf{2}] 多项式（Multinomial）分布，参数$\theta=\bm{\mu}$的最大似然估计结果等于样本均值，$\bm{\mu}_{\mathrm{ML}}=\sum_{i=1}^m \bm{x}_i/m$，
	
	\vspace{1mm}
	\begin{scriptsize}
	\begin{spacing}{1.2}
	{\sffamily
	多项式分布所刻画的随机变量有$d$个可能的值，用$d$维独热（one-hot，即有且仅有一个元素为1，其它为0）向量$\bm{x}$表示。记$x_j=1$的概率为$\mu_j$，则有
	
	\begin{equation*}
	p(\bm{x}|\bm{\mu}) = \prod_{j=1}^d \mu_j^{x_j}\ \ \ \ \mathit{s.t.}\ \ \sum_{j=1}^d \mu_j=1,\ \forall j,\ \ \mu_j\geq 0
	\end{equation*}

	对应的对数似然函数为
	\begin{equation*}
	\log L(S;\theta) = \sum_{i=1}^m \log p(\bm{x}_i;\theta) = \sum_{i=1}^m \sum_{j=1}^d x_{ij} \log \mu_j
	\end{equation*}
使用拉格朗日乘子$\lambda$，最大化对数似然等价于最大化如下函数：$L' = \log L(S;\theta) + \lambda \left( \sum_{j=1}^d \mu_j - 1 \right) $。对$\mu_j$求导并令导函数为0，可以得到：
	\begin{equation*}
	\frac{\partial L'}{\partial \mu_j} = \sum_{i=1}^m\frac{x_{ij}}{\mu_j} + \lambda = 0  \Longrightarrow	 \mu_{j,\mathrm{ML}} = -\sum_{i=1}^m x_{ij}/\lambda
	\end{equation*}
注意到，$\sum_{j=1}^d \mu_j=-m/\lambda=1$，可以得到$\lambda=-m$。从而
	\begin{equation*}
	\bm{\mu}_{\mathrm{ML}} = \frac{1}{m}\sum_{i=1}^m \bm{x}_i
	\end{equation*}
	}
	\end{spacing}
	\end{scriptsize}
	\vspace{-4mm}
	
	\item [\textbf{3}] 高斯（Gaussian）分布，参数$\theta=(\bm{\mu},\bm{\Sigma})$，最大似然估计分别为样本均值与方差。
	\vspace{1mm}
	\begin{scriptsize}
	\begin{spacing}{1.2}
	{\sffamily
	高斯分布函数为
	\begin{equation*}
	p(\bm{x}) = \frac{1}{(2\pi)^{d/2} |\bm{\Sigma}|^{1/2}} \exp \left\{ -\frac{1}{2} (\bm{x} - \bm{\mu})^\top \bm{\Sigma}^{-1} (\bm{x} - \bm{\mu})\right\}
	\end{equation*}
	
	对应的对数似然函数为
	\begin{equation*}
	\log L(S;\theta) = \sum_{i=1}^m \log p(\bm{x}_i;\theta) 
	= \frac{-md}{2} \log (2\pi) - \frac{m}{2}\log |\bm{\Sigma}| - \frac{1}{2} \sum_{i=1}^m (\bm{x}_i - \bm{\mu})^\top \bm{\Sigma}^{-1} (\bm{x}_i - \bm{\mu})
	\end{equation*}
	对$\bm{\mu}$求导并令导函数为0，可以得到
	\begin{equation*}
	\bm{\mu}_{\mathrm{ML}}= \frac{1}{m} \sum_{i=1}^m \bm{x}_i
	\end{equation*}
	
	对$\bm{\Sigma}$求导并令导函数为0，可以得到（此处不严格证明$\bm{\Sigma}$为对称阵）：
	\begin{equation*}
	\frac{\partial \log L(S;\theta)}{\partial \bm{\Sigma}} = -\frac{m}{2} (\bm{\Sigma}^{-1})^\top + \frac{1}{2} \sum_{i=1}^m  \bm{\Sigma}^{-1} (\bm{x}_i - \bm{\mu})(\bm{x}_i - \bm{\mu})^\top \bm{\Sigma}^{-1} \Rightarrow \bm{\Sigma}_{\mathrm{ML}} = \frac{1}{m}\sum_{i=1}^m (\bm{x}_i - \bm{\mu}_{\mathrm{ML}})(\bm{x}_i - \bm{\mu}_{\mathrm{ML}})^\top
	\end{equation*}
	\textit{\underline{注1}}：估计$\bm{\Sigma}$需要用到以下性质：	
	\begin{itemize}
	\item $tr[\bm{A}\bm{B}\bm{C}]=tr[\bm{C}\bm{A}\bm{B}]=tr[\bm{B}\bm{C}\bm{A}]$；
	\item $\bm{x}^\top \bm{A} \bm{x}$是标量，它的迹是它本身，因此$\bm{x}^\top \bm{A} \bm{x} = tr[\bm{x}^\top \bm{A} \bm{x}] = tr[\bm{x} \bm{x}^\top \bm{A}]$；
	\item $\partial tr[\bm{A} \bm{B}]/\partial \bm{A} = \bm{B}^\top$; $\partial \log |\bm{A}|/\partial \bm{A} = (\bm{A}^{-1})^\top$; $\partial tr(\bm{A}\bm{X}^{-1}\bm{B})/\partial \bm{X} = -(\bm{X}^{-1} \bm{BA}\bm{X}^{-1})^\top$
	\end{itemize}
	}
	\end{spacing}
	\end{scriptsize}
	\vspace{-2mm}
	
	\item [\textbf{4}] 指数分布族（Exponential family）的极大似然估计结果由特征函数的均值给出。
	
	上述例子都是指数分布族的特例。满足如下形式的分布均属于指数分布族：
	\begin{equation}
	p(\bm{x}|\bm{\eta}) = h(\bm{x}) \exp\{ \bm{\eta}^\top \bm{u}(\bm{x}) - A(\bm{\eta}) \}
	\end{equation}

	\begin{scriptsize}
	\begin{spacing}{1.2}
	{\sffamily

	对数似然函数为：
	
	\begin{equation*}
	\log L(S;\theta) = \sum_{i=1}^m \log h(\bm{x}_i) + \bm{\eta}^\top \sum_{i=1}^m u(\bm{x}_i) - \sum_{i=1}^m A(\bm{\eta})
	\end{equation*}
对$\bm{\eta}$求导并令导函数为0，得到$\frac{\partial A(\bm{\eta})}{\partial \bm{\eta}} = \sum_{i=1}^m u(\bm{x}_i)/m$。结合下面的注，在具体分布中，求得配分函数$A(\bm{\eta})$和特征函数$u(\bm{x})$，即可得到对应的$\bm{\eta}_\mathrm{ML}$。
	
	此外，利用分布函数积分为1的性质进行求导，可以得到：
	\begin{equation*}
	\int  h(\bm{x}) \exp\{ \bm{\eta}^\top \bm{u}(\bm{x}) - A(\bm{\eta}) \} \left(\bm{u}(\bm{x}) - \frac{\partial A(\bm{\eta})}{\partial \eta} \right) = 0  \Rightarrow \frac{\partial A(\bm{\eta})}{\partial \bm{\eta}} = \mathbb{E} [u(\bm{x})]
	\end{equation*}

因此，$\sum_i u(\bm{x}_i)$称为充分统计量。此外，$u(\bm{x})$的方差可以通过$A(\bm{\eta})$二阶导表示，其它高阶统计矩亦然。事实上，对于指数分布族，只要我们找到配分函数对其归一化，就能通过微分计算其统计矩。
	
	\textit{\underline{注2}}：伯努利分布：$p(x|\theta) = \theta^x(1-\theta)^{1-x} 
	= \exp\left\{ \log \left( \frac{\theta}{1-\theta}\right) x + \log(1-\theta)\right\}$，对比可得：
	$h(x)=1$，$u(x)=x$，$\eta=\log \frac{\theta}{1-\theta} $，$A(\eta)=\log (1+\exp(\eta))$。

	\textit{\underline{注3}}：多项式分布：注意到，由于$\sum_{j=1}^d \mu_d = 1$，多项式分布事实上有$d-1$个参数，
	\begin{equation*}
	\begin{split}
	p(\bm{x}|\bm{\mu}) &= \prod_{j=1}^d \mu_j^{x_j} = \exp\left\{ \sum_{j=1}^d x_j \log \mu_j \right\} = \exp\left\{ \sum_{j=1}^{d-1} x_j \log \mu_j + \left(1-\sum_{j=1}^{d-1} x_j \right) \log \left(1-\sum_{j=1}^{d-1} \mu_j \right) \right\} \\
	&= \exp\left\{ \sum_{j=1}^{d-1} x_j \log \left( \frac{\mu_j}{1-\sum_{k=1}^{d-1} \mu_k} \right) +  \log \left(1-\sum_{j=1}^{d-1} \mu_j \right) \right\}
	\end{split}
	\end{equation*}
令$\eta_j =  \log \left(\mu_j/(1-\sum_{k=1}^{d-1} \mu_k)\right)$，则有$\mu_j = \left(\exp\eta_j / (1+\sum_{k=1}^{d-1} \exp \eta_k)\right)$，且$1-\sum_{j=1}^{d-1} \mu_j =\left(1 / (1+\sum_{k=1}^{d-1} \exp \eta_k)\right)$。对比可得：$h(\bm{x})=1, u(\bm{x})=\bm{x}, A(\bm{\eta})=\log (1+\sum_{k=1}^{d-1} \exp \eta_k)$.
	
	\textit{\underline{注4}}：高斯分布：对比可得$h(\bm{x})=(2\pi)^{-d/2}, u(\bm{x})=(1, \bm{x}, \bm{x}\bm{x}^\top)^\top, \bm{\eta}=(-\frac{1}{2} \bm{\mu}^\top \bm{\Sigma}^{-1} \bm{\mu}-\frac{1}{2}\log|\bm{\Sigma}|, \bm{\Sigma}^{-1}\bm{\mu}, -\frac{1}{2} \bm{\Sigma}^{-1})^\top$。
	}
	\end{spacing}
	\end{scriptsize}
	\vspace{-2mm}
	\end{itemize}

\section{从MLE到贝叶斯推理}

	从上述结果直观来看，MLE对小数据集容易过拟合。定义参数$\theta$关于样本$\bm{x}$的经验损失为负对数似然
	
	\begin{equation*}
	l(\theta,\bm{x}) = -\log \mathcal{P}_{\theta}(\bm{x})
	\end{equation*}
则MLE等价于ERM。然而，根据真实分布$\mathcal{P}$，参数$\theta$的真实风险为：
	
	\begin{equation*}
	\mathbb{E}[l(\theta, \bm{x})] =	-\sum_{\bm{x}} \mathcal{P}(\bm{x}) \log \mathcal{P}_{\theta}(\bm{x}) = 
	\sum_{\bm{x}} \mathcal{P}(\bm{x}) \log \left( \frac{\mathcal{P}(\bm{x})}{\mathcal{P}_{\theta}(\bm{x})} \right) +
	\sum_{\bm{x}} \mathcal{P}(\bm{x}) \log \frac{1}{\mathcal{P}(\bm{x})} \geq  \sum_{\bm{x}} \mathcal{P}(\bm{x}) \log \frac{1}{\mathcal{P}(\bm{x})} 
	\end{equation*}
等号成立当且仅当$\mathcal{P}=\mathcal{P}_{\theta}$。某些情况下，容易证明MLE可以达到较低的真实误差，例如，在已知高斯分布的方差情况下估计其均值，有

	\begin{equation*}
\mathop{\mathbb{E}}\limits_{\bm{x}\sim\mathcal{N}(\bm{\mu}, \bm{\Sigma})}[l(\bm{\mu}_{\mathrm{ML}}, \bm{x})- l(\bm{\mu}, \bm{x})] =
\mathop{\mathbb{E}}\limits_{\bm{x}\sim\mathcal{N}(\bm{\mu}, \bm{\Sigma})}  \log \left( \frac{\mathcal{P}_{\bm{\mu}}(\bm{x})}{\mathcal{P}_{\bm{\mu}_{\mathrm{ML}}}(\bm{x})}\right)
	= \frac{1}{2} (\bm{\mu}_{\mathrm{ML}}-\bm{\mu})^\top \bm{\Sigma}^{-1}(\bm{\mu}_{\mathrm{ML}}-\bm{\mu})
	\end{equation*}
可以看到，MLE估计得到的参数与真实分布的风险之间的差距是有界的。

	但是，另一方面，我们也想知道最坏的情况下MLE估计得到的参数真实风险如何。考虑服从伯努利分布的随机变量，假设参数$\theta$是一个较小的非零值。连续采样$m$个样本，取值都是0的概率为is $(1-\theta)^m\geq e^{-2m\theta}$。在这种情况下，$\theta_{\mathrm{ML}}=0$，其真实风险为$\mathbb{E}[l(\bm{\mu}_{\mathrm{ML}}, x)]=\theta \log l(\bm{\theta}_{\mathrm{ML}}, 1) + (1-\theta)  \log l(\bm{\theta}_{\mathrm{ML}}, 0) = \theta \log (1/\theta_{\mathrm{ML}}) = \infty$。
	
	为了解决这个问题，贝叶斯推理引入关于参数的先验分布$p(\theta)$。为了计算的简便，\textbf{通常希望后验分布与先验分布的函数形式相同}，称为\textbf{共轭性}，其先验称为\textbf{共轭先验}。
	
	\begin{itemize}
	\item [\textbf{1}] 伯努利分布的共轭先验是Beta分布
	
	\vspace{1mm}
	\begin{scriptsize}
	\begin{spacing}{1.2}
	{\sffamily
	选择先验通常观察似然函数的形式就可以得到（剩余的配分函数是为了保证先验分布归一化而已），后验分布也是通过保证其归一化得到的。
	
	已知服从伯努利分布的数据集的似然函数与$\mu^x (1-\mu)^{1-x}$成比例，因此先验分布应该与$\mu$和$1-\mu$的幂次成比例，才能保证先验与似然函数相乘之后，后验分布也与$\mu$和$1-\mu$的幂次成比例。Beta分布正好满足这一点。
	
	\begin{equation}
	\mathrm{Beta}(\mu|a,b)=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}
	\end{equation}
其中，$\Gamma(x)=\int^\infty_0 t^{x-1} e^{-t} \mathrm{d} t$保证了分布的归一化。后验分布具备如下形式： 
	\begin{equation*}
	p(\mu|S) \propto p(S|\mu) \mathrm{Beta}(\mu|a,b) = \mu^{a+\sum_{i=1}^m x_i-1}(1-\mu)^{m-\sum_{i=1}^m x_i + b-1}
	\end{equation*}
为了保证其归一化，后验分布必须为$\mathrm{Beta}(a+\sum_{i=1}^m x_i, b+m-\sum_{i=1}^m x_i)$。

    beta分布的均值为 $\mathbb{E}(\mu)=\frac{a}{a+b}$，因此预测$x=1$的概率（基于数据集$S$）由后验分布的均值给出，即
	\begin{equation*}
	p(x=1|S)=\int^1_0 p(x=1|\mu)p(\mu|S) \mathrm{d}\mu = \int^1_0 \mu p(\mu|S) \mathrm{d}\mu = \mathbb{E}(\mu|S) = \frac{a+\sum_{i=1}^m x_i}{b+m}
	\end{equation*}
注意到，$S$可以包含无穷样本，即$m\rightarrow\infty$，因此上述结果收敛于$\frac{\sum_{i=1}^m x_i}{m}$，与MLE相同。
	}
	\end{spacing}
	\end{scriptsize}
	\vspace{-2mm}
	
	\item [\textbf{2}] 多项式分布的共轭先验是迪利克雷（Dirichlet）分布

	\vspace{1mm}
	\begin{scriptsize}
	\begin{spacing}{1.2}
	{\sffamily
	观察似然函数的形式，先验函数应该形如：$p(\bm{\mu}|\bm{\alpha})\propto \prod_{j=1}^d \mu_j^{\alpha_j-1}$，其中$0\leq\mu_k\leq 1$。令$\alpha_0=\sum_{j=1}^d \alpha_j$，其归一化形式即为迪利克雷分布：
	
	\begin{equation*}
	\mathrm{Dir} (\bm{\mu}|\bm{\alpha}) = \frac{\Gamma(\alpha_0)}{\Gamma(\alpha_1)\cdots\Gamma(\alpha_d)}  \prod_{j=1}^d \mu_j^{\alpha_j-1}
	\end{equation*}
	
	后验分布为：
	\begin{equation*}
	p(\bm{\mu}|S) \propto p(S|\bm{\mu}) \mathrm{Dir} (\bm{\mu}|\bm{\alpha}) =\prod_{i=1}^m \prod_{j=1}^d \mu_j^{x_{ij}} \prod_{j=1}^d \mu_j^{\alpha_j-1} \overset{m_j:=\sum_{i=1}^m x_{ij}}{\Longrightarrow}  \prod_{j=1}^d \mu_j^{m_j+\alpha_j-1} = \mathrm{Dir} (\bm{\mu}|\bm{\alpha}+\bm{m})
	\end{equation*}
	}
	\end{spacing}
	\end{scriptsize}
	\vspace{-2mm}
	
	\item [\textbf{3}] Gaussian distribution

	\vspace{1mm}
	\begin{scriptsize}
	\begin{spacing}{1.2}
	{\sffamily
	对于高斯分布，仅讨论已知方差估计期望的情况，期望的共轭先验也是高斯分布，
	\begin{equation*}
	p(\bm{\mu}|\bm{\mu}_0, \bm{\Sigma}_0)=\mathcal{N}(\bm{\mu}|\bm{\mu}_0, \bm{\Sigma}_0)
	\end{equation*}
其后验分布具有如下形式：
	\begin{equation*}
	\begin{split}
	& \log p(\bm{\mu}|S) \propto \log p(\bm{\mu}|\bm{\mu}_0, \bm{\Sigma}_0) + \log p(S|\bm{\mu}) \\
	&= -\frac{1}{2} \sum_{i=1}^m  (\bm{x}_i-\bm{\mu})^\top \bm{\Sigma}^{-1}  (\bm{x}_i-\bm{\mu}) -\frac{1}{2}(\bm{\mu}-\bm{\mu}_0)^\top \bm{\Sigma}_0^{-1} (\bm{\mu}-\bm{\mu}_0) \\
	&= -\frac{1}{2} \left[ \bm{\mu}^\top (m\bm{\Sigma}^{-1} + \bm{\Sigma}_0^{-1}) \bm{\mu} - 2 \bm{\mu}^\top \left(\bm{\Sigma}^{-1} \sum_{i=1}^m \bm{x}_i + \bm{\Sigma}_0^{-1} \bm{\mu}_0\right) + \bm{\mu}_0^\top \bm{\Sigma}_0^{-1} \bm{\mu}_0 + \sum_{i=1}^m \bm{x}_i^\top \bm{\Sigma}^{-1} \bm{x}_i\right]
	\end{split}
	\end{equation*}
归一化后可以给出后验分布$\mathcal{N}(\bm{\mu}_1,\bm{\Sigma}_1)$，其中$\bm{\Sigma}_1^{-1}=m\bm{\Sigma}^{-1} + \bm{\Sigma}_0^{-1}$，$\bm{\mu}_1=\bm{\Sigma}_1(\bm{\Sigma}^{-1} \sum_{i=1}^m \bm{x}_i + \bm{\Sigma}_0^{-1} \bm{\mu}_0)$.
	}
	\end{spacing}
	\end{scriptsize}
	\vspace{-2mm}
	
	\end{itemize}
	
\section{局部观测数据的极大似然——最大化期望（Expectation Maximization，EM）}
	Until now, a training sequence is $\{(\bm{x}_1,y_1),\cdots,(\bm{x}_m,y_m)\}$, in which $y_i$ is the latent factor that depends whether $\rm{x}_i$ is sampled from. However, if the latent factors are not observed, the likelihood of the sequence $\{\bm{x}_1,\cdots,\bm{x}_m\}$ is:
	\begin{equation*}
	L(S;\theta) = \prod_{i=1}^m \sum_{j=1}^k p_\theta(\bm{x}_i,y_j) = \prod_{i=1}^m \sum_{j=1}^k p_\theta(\bm{x}_i|y_j)p_\theta(y_j)
	\end{equation*}
	The maximum-likelihood estimator is therefore the solution of the maximization problem:
	\begin{equation}
	\log L(S;\theta) = \sum_{i=1}^m \log \sum_{j=1}^k p_\theta(\bm{x}_i|y_j)p_\theta(y_j)
	\end{equation}
	
	In the E-step, we use the current parameter values $\theta^{\mathrm{old}}$ to find the posterior distribution of the latent variables given by $p(\bm{Y}|\bm{X}, \theta^{\mathrm{old}})$. We then use this posterior distribution to find the expectation of the complete-data log likelihood evaluated for some general parameter value $\theta$. This expectation, denoted , is given by
	
	\subsection{EM算法求解高斯混合模型（Gaussian Mixture Model，GMM）}
	
	GMM (Gaussian mixture models) is a typical example, with parameters comprising the means and covariances of the components and the mixing coefficients. Its log-likelihood function (plus a Lagrange multiplier) is given by
	\begin{equation*}
	\sum_{i=1}^m \log \sum_{j=1}^k \pi_j \mathcal{N} (\bm{x}_i|\bm{\mu}_j,\bm{\Sigma}_j) + \lambda \left(\sum_{j=1}^k \pi_j - 1\right)
	\end{equation*}
	Take derivatives with regard to $\bm{\mu}_k$ and set it to zero
	
	\begin{equation}
	\label{eq:GMM_mu}
	\sum_{i=1}^m \underbrace{\frac{\pi_j  \mathcal{N} (\bm{x}_i|\bm{\mu}_j,\bm{\Sigma}_j)}{\sum_l \pi_l \mathcal{N} (\bm{x}_i|\bm{\mu}_l,\bm{\Sigma}_l)}}_{z_{ij}} \bm{\Sigma}_k (\bm{x}_i - \bm{\mu}_j) \Longrightarrow \bm{\mu}_j=\frac{\sum_{i=1}^m z_{ij} \bm{x}_i}{\sum_{i=1}^m z_{ij}}
	\end{equation}
in which $z_{ij}=p(y_j=1|\bm{x}_i)$ is the posterior probability. Similarly,
	\begin{equation}
	\label{eq:GMM_sigma}
	\bm{\Sigma}_j=\frac{\sum_{i=1}^m z_{ij} (\bm{x}_i-\bm{\mu}_j)(\bm{x}_i-\bm{\mu}_j)^\top}{\sum_{i=1}^m z_{ij}}
	\end{equation}
	Then, take derivatives with regard to each $\pi_j$ and set it to zero
	\begin{equation*}
	\sum_{i=1}^m \frac{\mathcal{N} (\bm{x}_i|\bm{\mu}_j,\bm{\Sigma}_j) }{\sum_l \pi_l \mathcal{N} (\bm{x}_i|\bm{\mu}_l,\bm{\Sigma}_l)} + \lambda = \sum_{i=1}^m \frac{z_{ij}}{\pi_j} + \lambda \Longrightarrow \pi_j=-\frac{\sum_{i=1}^m z_{ij}}{\lambda}
	\end{equation*}
With the constraint that $\sum_{j=1}^k\pi_j=-\sum_{i=1}^m\sum_{j=1}^k z_{ij}/\lambda = -m/\lambda=1$, then $\lambda=-m$, and hence

	\begin{equation}
	\label{eq:GMM_pi}
	\pi_j=\frac{\sum_{i=1}^m z_{ij}}{m}
	\end{equation}
	
	It means that the mixing coefficient for the $k$-th component is given by the average posterior which that component takes for explaining the data points. Notes that the calculation above drops into a circle form: $\bm{\mu}, \bm{\Sigma} \rightarrow z_{ij} \rightarrow \bm{\mu}, \bm{\Sigma}$, hence we must do it in an iterative way, which is the EM algorithm for GMM:
	
	
	\begin{minipage}{.9\linewidth}
    \begin{itemize}
	\item fix $k$, the number of Gaussian components;
	\item initialize: $\forall j=1,\cdots,k, z_{ij}=\frac{1}{k},$ and $\pi_j=\frac{1}{k}$;
	\item M-step, solve $\bm{\mu}, \bm{\Sigma}$ according to \textit{Eq.}\ref{eq:GMM_mu} and \textit{Eq.}\ref{eq:GMM_sigma};
	\item E-step, solve $z_{ij},\pi_i$ according to \textit{Eq.}\ref{eq:GMM_pi}.
	\item Repeat E-M step until convergence.
	\end{itemize}
  	\end{minipage}

		
\section{与判别式模型的比较}
	\label{sec:final}
	生成式模型为数据的潜在分布假定一个参数形式，将学习问题转化为参数估计。但是，在判别式模型中，学习目标是直接估计判别函数的参数。
	
	显然，如果参数估计成功，利用生成式模型直接获得贝叶斯分类器是可靠的。但问题是，逼近潜在分布往往比学习一个判别器难得多（因为逼近潜在分布更加靠近学习问题的本质）。Vladimir Vapnik因此说：
	\begin{center}
	\textbf{在解决问题的时候，不应该将一个更加一般化的问题作为其中间步骤。}\textit{"When solving a given problem, try to avoid a more general problem as an intermediate step."}
	\end{center}

	However, in some situations, it is reasonable to adopt the generative models. Sometimes it is easier (computationally) to estimate the parameters of the model than to learn a discriminative predictor. Additionally, in some cases we do not have a specific task at hand but rather would like to use the data at a later time.
	
	Modern generative models have another big goal, that is to 'generate' (sample from the underlying distribution) data like that in reality. The intuition behind this approach follows a famous quote from Richard Feynman:	
	\begin{center}
	\textit{"What I cannot create, I do not understand."}
	\end{center}

	\subsection{Naive Bayes to linear discriminant models}
	The usual assumption in Naive Bayes classifier is that each conditional probability $p(X=\bm{x}|Y=y)$ is a Gaussian distribution. Consider the binary classification task, denote the two conditional distribution as $\mathcal{N}(\bm{\mu}_0,\bm{\Sigma}_0)$, $\mathcal{N}(\bm{\mu}_1,\bm{\Sigma}_1)$, we will predict $h_{\mathrm{Bayes}}(\bm{x})=1$ iff.
	
	\begin{equation*}
	\begin{split}
	&\frac{p(Y=0) p(X=\bm{x}|Y=0)}{p(Y=1) p(X=\bm{x}|Y=1)} > 1 \\
	\iff &\log \frac{p(Y=0)}{p(Y=1)} + \log p(X=\bm{x}|Y=0) - \log p(X=\bm{x}|Y=1) > 0 \\
	\iff &\bm{x}^\top ( \bm{\Sigma}_1^{-1} - \bm{\Sigma}_0^{-1}) \bm{x} + 2 (\bm{\mu}_0^\top\bm{\Sigma}_0^{-1} - \bm{\mu}_1^\top\bm{\Sigma}_1^{-1}) \bm{x} + \underbrace{\bm{\mu}_1^\top\bm{\Sigma}_1^{-1}\bm{\mu}_1 - \bm{\mu}_0^\top\bm{\Sigma}_0^{-1}\bm{\mu}_0 + \log\frac{|\bm{\Sigma}_1|}{|\bm{\Sigma}_0|} + 2\log \frac{p(Y=0)}{p(Y=1)}}_{\mathrm{b}} > 0
	\end{split}
	\end{equation*}
which is a quadratic discriminant function. Further, if we assume that $\bm{\Sigma}_0=\bm{\Sigma}_1=\bm{\Sigma}$, the classifier can be simplified to be a linear discriminant function $\bm{w}\cdot\bm{x}+b$, with $\bm{w}=2(\bm{\mu}_0 - \bm{\mu}_1)^\top\bm{\Sigma}^{-1}$ and $b=\bm{\mu}_1^\top\bm{\Sigma}^{-1}\bm{\mu}_1 - \bm{\mu}_0^\top\bm{\Sigma}^{-1}\bm{\mu}_0+ 2\log \frac{p(Y=0)}{p(Y=1)}$. If the prior probability is equal, namely $p(Y=0)=p(Y=1)$, the bias term can be further simplified.
	
\section{Exercises and solutions}
\begin{itemize}
\item[Ex1] \textbf{K-means} (see \textit{UML Chapter 22.2, PRML Chapter 9.1}). K-means is a simple but important clustering algorithm. In fact, GMM is sometimes called \textit{soft} K-means. As a hard version, K-means assigns the most probable cluster label to an example (\textit{i.e.}, $z_{ij}=1$ for one of $j\in{1,\cdots,k}$ but 0 for others), and calculate the mean and covariance based on the in-cluster instead of global data. Formally, its procedure is as below,

	\begin{minipage}{.9\linewidth}
    \begin{itemize}
	\item[•] fix $k$, the number of clusters;
	\item[•] randomly choose initial clustering centers $\bm{\mu}^0_1,\cdots,\bm{\mu}^0_k$
	\item[•] loop from $t=0$ to $max\_iter$
	\item[•] 1. $\forall i\in \{1,\cdots,m\}$, determine $j=\arg\min_{j} d(\bm{x}_i, \bm{\mu}_j^t)$ and set $z_{ij}^t=1$;
	\item[•] 2. $\forall j\in \{1,\cdots,k\}$, update $\bm{\mu}_j^{t+1} = \frac{\sum_{i=1}^m \bm{x}_i z^t_{ij}}{\sum_{i=1}^m z^t_{ij}} $;
	\end{itemize}
  	\end{minipage}

in which $d(\cdot,\cdot)$ can be arbitrary distance function. Note that the step 1. corresponds to M-step of GMM, and step 2 corresponds to E-step. For GMM, the objective is to maximize likelihood, and for k-means, the objective can be viewed as minimizing the sum of in-cluster distance (if we choose the distance to be Euclidean distance, the loss is also called Sum of in-cluster Square Error, \textit{a.k.a.}, SSE):
	\begin{equation*}
	C = \min_{\bm{\mu}_1,\cdots,\bm{\mu}_k} \sum_{j=1}^k \sum_{i=1, z_{ij}=1}^m d(\bm{x}_i, \bm{\mu}_j)
	\end{equation*}
Now, prove that: each iteration of the k-means algorithm does not increase the objective.

\item[] \textbf{Solution}: According to the iteration, 
	
	\begin{equation*}
	C^t = \sum_{j=1}^k \sum_{i=1, z^t_{ij}=1}^m d(\bm{x}_i, \bm{\mu}^{t+1}_j) \leq \sum_{j=1}^k \sum_{i=1, z^t_{ij}=1}^m d(\bm{x}_i, \bm{\mu}^t_j)  \leq \sum_{j=1}^k \sum_{i=1, z^{t-1}_{ij}=1}^m d(\bm{x}_i, \bm{\mu}^t_j) = C^{t-1}
	\end{equation*}

\item[Ex2] \textbf{Simplex of Dirichlet distribution} Because of the summation constraint, the distribution over the space of the $\{\mu_j\}$ is confined to a simplex of dimensionality $d-1$.

\item[Ex3] \textbf{Sequential estimation} (see \textit{PRML Chapter 2.3.5}).

\item[Ex4] \textbf{Sequential estimation under the perspective of Bayesian reasoning} (see \textit{PRML Chapter 2.3.5}).

\item[Ex5] \textbf{Unbiased estimation} (UML Ex24.1) $\theta_{\mathrm{ML}}$, in intrinsic, is a function of observed random variables, and hence has its expectation. If the expectation of an estimation is exactly the parameter in theory, we say that the estimation is unbiased. In the case of exponential family, 
	\begin{equation*} 
	\mathbb{E} (\mu_\mathrm{ML}) = \mathbb{E} \left(\frac{\sum_{i=1}^m x_i}{m}\right) =  \sum_{i=1}^m  \frac{\mathbb{E}(x_i)}{m} = \mathbb{E}(x) = \mu
	\end{equation*}
Hence, we say that the MLE for mean parameter is unbiased. Now, prove that the maximum likelihood estimator of the variance of a Gaussian variable is biased.

\item[] \textbf{Solution}:
	\begin{equation*}
	\mathbb{E} (\bm{\Sigma}_\mathrm{ML}) = \sum_{i=1}^m  \frac{\mathbb{E}((\bm{x}_i - \bm{\mu}_\mathrm{ML})(\bm{x}_i - \bm{\mu}_\mathrm{ML})^\top)}{m}
	= \sum_{i=1}^m  \frac{\mathbb{E}(\bm{x}_i \bm{x}_i^\top) + \mathbb{E}(\bm{\mu}_\mathrm{ML} \bm{\mu}_\mathrm{ML}^\top) - 2\mathbb{E}(\bm{\mu}_\mathrm{ML} \bm{x}_i^\top)}{m}
	\end{equation*}
	Consider each term in the numerator, note that each pair of samples is independent,
	\begin{scriptsize}
	\begin{equation*}
	\begin{split}
	&\mathbb{E}(\bm{x}_i \bm{x}_i^\top) = \bm{\Sigma} + \bm{\mu}\bm{\mu}^\top  \\
	&\mathbb{E}(\bm{\mu}_\mathrm{ML} \bm{\mu}_\mathrm{ML}^\top) = 
	\frac{1}{m^2} \mathbb{E}\left(\sum_{i=1}^m \sum_{j=1}^m \bm{x}_i \bm{x}_j^\top\right)
	= \frac{1}{m^2} \mathbb{E}\left(\sum_{i=1}^m \sum_{j=1}^m (\bm{x}_i-\bm{\mu}) (\bm{x}_j-\bm{\mu})^\top + 2\bm{\mu} \sum_{i=1}^m (\bm{x}_i-\bm{\mu})^\top + \sum_{i=1}^m\sum_{j=1}^m \bm{\mu}\bm{\mu}^\top \right) 
	= \frac{\bm{\Sigma}}{m} + \bm{\mu}\bm{\mu}^\top \\
	&\mathbb{E}(\bm{\mu}_\mathrm{ML} \bm{x}_i^\top) =  \mathbb{E} \left(\frac{1}{m}\sum_{j=1}^m \bm{x}_j \bm{x}_i^\top \right)
	= \frac{1}{m} \mathbb{E} \left(\sum_{j=1}^m (\bm{x}_j-\bm{\mu})(\bm{x}_i-\bm{\mu})^\top + 2\bm{\mu}\sum_{j=1}^m (\bm{x}_j-\bm{\mu})^\top + \sum_{j=1}^m \bm{\mu} \bm{\mu}^\top\right) = \frac{\bm{\Sigma}}{m} + \bm{\mu} \bm{\mu}^\top
	\end{split}
	\end{equation*}
	\end{scriptsize}
Hence, $\mathbb{E} (\bm{\Sigma}_\mathrm{ML}) = \frac{m-1}{m} \bm{\Sigma}$ which is biased.

\item[Ex6] \textbf{The connection between smoothing and regularized MLE} (UML Ex24.2)  Consider the following regularized
loss minimization for parameter estimation in the case of Bernoulli distribution:
	\begin{equation*}
	\min \frac{1}{m}\sum_{i=1}^m -\log \mathcal{P}_{\bm{\mu}}(\bm{x}_i) + \frac{1}{m} (\log(1/\mu)+\log(1/(1-\mu)))
	\end{equation*}
	
	\begin{itemize}
	\item[6.1] Show that the preceding objective is equivalent to the usual empirical error had we added two pseudo-examples to the training set.
	\item[6.2] Derive a high probability bound on $|\mu'-\mu|$, and use this to bound the true risk.  
	\end{itemize}

\item[] \textbf{Solution}:
	\begin{itemize}
	\item[6.1] The regularized loss can be written as 
	\begin{equation*}
	-\frac{1}{m}\sum_{i=1}^m x_i\log \mu + (1-x_i)\log(1-\mu) - \frac{1}{m} (\log( \mu)+\log(1- \mu))
	\end{equation*}
Take derivatives with regard to $\mu$ and set it to zero leads to $\mu'=\frac{1+\sum_{i=1}^m x_i}{m+2}$. It's equivalent to adding two pseudo-examples $\{0,1\}$ into the training set, which is called 'add-1' smoothing.
	\item[6.2] Using triangle inequality,
	\begin{equation*}
	|\mu'-\mu| = |\mu'-\mathbb{E}(\mu')+\mathbb{E}(\mu')-\mu| \leq |\mu'-\mathbb{E}(\mu')| + |\mathbb{E}(\mu')-\mu|
	\end{equation*}

	Since $\mathbb{E}(\mu')=\frac{1+m\mu}{m+2}$, we have that $|\mathbb{E}(\mu')-\mu|\leq \frac{1}{m+2}$, and $|\mu'-\mathbb{E}(\mu')|=\frac{m}{m+2}|\frac{1}{m}\sum_{i=1}^m x_i -\mu|$. Following Hoeffding's inequality, for any $\epsilon>0$, 
	
	\begin{equation*}
	P\left(|\mu'-\mu|\geq \frac{1}{m+2} +\epsilon \right) \leq 2\exp\left( -2m\epsilon^2 \right)
	\end{equation*}
	
	\end{itemize}


\end{itemize}
\textit{
	Chapter 4. Linear models for classification and regression, penalization \\
	  Chapter 5. Decision stumps, ensemble learning, Bayes PAC \\
      Chapter 6. Perceptron, MLP, deep learning, Generalization bounds on deep learning.}

\end{document}